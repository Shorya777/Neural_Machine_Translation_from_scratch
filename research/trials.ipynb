{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-lrXpDF5kgx",
        "outputId": "6c3f13b4-f28b-42ca-dd97-a48d6ce0e75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10125706\n",
            "[\"However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles\\n\", 'Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.\\n', 'The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.\\n', 'Mithali To Anchor Indian Team Against Australia in ODIs\\n', 'After the assent of the Honble President on 8thSeptember, 2016, the 101thConstitutional Amendment Act, 2016 came into existence\\n']\n",
            "10125706\n",
            "['आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।\\n', 'और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है\\n', 'जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।\\n', 'आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को\\n', '8 सितम्\\u200dबर, 2016 को माननीय राष्\\u200dट्रपति की स्\\u200dवीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्\\u200dव में आया\\n']\n"
          ]
        }
      ],
      "source": [
        "filepath_en = 'train.en'\n",
        "filepath_hi = 'train.hi'\n",
        "\n",
        "with open(filepath_en, encoding='utf-8') as file:\n",
        "    lines_en = file.readlines()\n",
        "print(len(lines_en))\n",
        "print(lines_en[:5])\n",
        "\n",
        "with open(filepath_hi, encoding='utf-8') as file:\n",
        "    lines_hi = file.readlines()\n",
        "\n",
        "print(len(lines_hi))\n",
        "print(lines_hi[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUOig1EV5kgx",
        "outputId": "90f6e3fe-524b-47ec-ba61-579426b52f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"however, paes, who was partnering australia's paul hanley, could only go as far as the quarterfinals where they lost to bhupathi and knowles\", 'whosoever desires the reward of the world, with allah is the reward of the world and of the everlasting life. allah is the hearer, the seer.', 'the value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.', 'mithali to anchor indian team against australia in odis', 'after the assent of the honble president on 8thseptember, 2016, the 101thconstitutional amendment act, 2016 came into existence']\n",
            "================================\n",
            "['आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।', 'और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है', 'जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।', 'आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को', '8 सितम्\\u200dबर, 2016 को माननीय राष्\\u200dट्रपति की स्\\u200dवीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्\\u200dव में आया']\n"
          ]
        }
      ],
      "source": [
        "TOTAL_SENTENCES = 200000\n",
        "english_sentences = lines_en[:TOTAL_SENTENCES]\n",
        "hindi_sentences = lines_hi[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "hindi_sentences = [sentence.rstrip('\\n') for sentence in hindi_sentences]\n",
        "\n",
        "print(english_sentences[:5])\n",
        "print(\"================================\")\n",
        "print(hindi_sentences[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OOIXt1O_BAv",
        "outputId": "aa80d18b-459f-48b3-8760-7619088747c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in hindi_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drEPgCVEDAMJ"
      },
      "outputs": [],
      "source": [
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\' ', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "hindi_vocabulary = [START_TOKEN, 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ',\n",
        "    'क', 'ख', 'ग', 'घ', 'ङ','ड़', 'च', 'छ', 'ज', 'झ', 'ञ',\n",
        "    'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न',\n",
        "    'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श',\n",
        "    'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ै', 'ो', 'ौ',\n",
        "    'ं', 'ः', 'ँ', '्', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '|',\n",
        "    ':', '<', '=', '>', '?', '@',\n",
        "    '[', '\\' ', ']', '^', '_', '`',\n",
        "    ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','\\u200d','।', 'ृ',\n",
        "    PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qpZWhY7AA5K",
        "outputId": "aa67f31f-c3a5-481d-a43b-11844a2e6c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 200000\n",
            "Number of valid sentences: 151260\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 250\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(hindi_sentences)):\n",
        "    hindi_sentence, english_sentence = hindi_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(hindi_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(hindi_sentence, hindi_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(hindi_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMN2l2qPHqq6",
        "outputId": "8f022bc8-2045-4db6-b9e8-487102f19274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Characters in the sentences not in the vocabulary: {'現', 'ಮ', 'j', 'z', 'а', 'ᐅ', 'ז', 'س', '\\ue208', '郑', '§', 'K', 'P', 'ː', '্', 'ग़', 'æ', 'រ', 'þ', '්', 'ו', '車', 'ਤ', 'پ', 'ऑ', 'ਰ', '\\uf0b7', 'ท', 'ோ', 'য', '£', 'я', 'ಯ', 'ч', 'ֶ', '\\uf642', '□', 'a', 'о', 'ස', 'ל', 'ä', 'ţ', 'ę', 'ট', '\\u2061', 'ế', 'ᠠ', 'ऎ', 'A', '“', 'ب', 'ុ', 'Ć', 'פ', 'ย', '⚡', '₹', 'ö', '洞', 'Ż', '魯', 'ַ', 'ᓗ', 'ב', 'ل', 'μ', '⋅', 'ග', 'ঙ', 'ě', 'ִ', '林', 'ស', '\\xad', 'ਸ', 'ನ', 'J', 'е', 'É', 'ො', 'ロ', 'ٓ', '庭', '⁻', 'H', 'জ', '̈', '̯', '西', 'ミ', '°', '\\u200e', 'Ō', 'í', 'O', 'ï', 'ක', 'λ', 'h', 'ה', '⊆', 'б', 'E', 'ּ', '域', '○', 'త', '©', 'ऽ', '్', 'ˈ', 'D', '’', 'ং', 'ಕ', 'ு', 'n', 'স', 'ඩ', '휴', 'ô', 'К', 'த', 'ó', 'ਵ', 'آ', 'ο', 'ॊ', 'ಿ', 'ō', '\\ufeff', 'ऌ', '의', '한', '್', 'ল', '℃', 'χ', 'パ', 'Â', '»', 'ऍ', 'চ', 'ی', 'Ò', 'ত', 'ម', 'β', 'ॆ', 'ع', 'C', 'ہ', '॥', '¸', 'ਦ', '្', '日', 'מ', 'ᠨ', '\\uf0d8', 'â', '›', 'إ', 'л', '班', 'ය', 'க', 'i', 'X', '夕', '에', '\\u200f', 'м', 'Г', '自', 'ದ', 'k', 'ه', 'ρ', 'Ę', '♦', 'ɵ', 'y', 'أ', '‚', 'េ', 'Ž', '€', '\\u2008', 'ε', 'ர', 'š', 'দ', 'א', 'ර', '\\ue5a0', 'ר', 'ィ', 'ช', 'כ', 'ー', '州', 'Q', 'ॄ', '鲁', '‘', 'ᐃ', 'á', '}', 'י', 'ळ', 'Δ', '章', '·', '้', 'U', 'д', 'ᒡ', 'ן', 'ֹ', 'ු', 'ʊ', '™', 'ң', 'ऩ', 'с', '明', 'গ', '\\u200b', 'Ô', 'e', 'é', 's', 'L', 'ḍ', 'พ', 'ا', 'и', '湖', 'c', '่', 'ט', '®', 'ª', 'I', '½', 'v', 'メ', '{', 'コ', '木', 'ు', 'ச', '관', 'ை', '唐', 'Ň', 'ñ', 'ظ', '⁰', '\\uf0a7', ';', 'p', 'l', '死', '×', 'ة', 'ॢ', 'م', '¨', 'আ', 'ి', 'ط', 'Я', 'ض', 'হ', 'b', 'ই', 'ˌ', 'ٕ', '☺', 'ப', 'ว', 'F', '•', 'ê', 'ឃ', 'ಚ', '․', 'ĺ', 'ְ', 'ප', 'à', 'ల', 'ص', '☻', 'ត', 'δ', '\\ue88c', 'С', 'Ê', '공', 'வ', '代', 'ৰ', 'È', '˝', 'ש', 'w', '„', '經', 'S', 'Ю', 'o', 'ල', 'υ', '動', 'শ', 'ក', 'u', 'ব', 'ॐ', '਼', '❑', '¬', 'ق', 'ৱ', '中', 'ॉ', 'ί', 'ೆ', 'ʔ', 'Ω', 'া', 'ʹ', '七', '−', '→', 'у', 'ī', '▪', 'G', 'ָ', 'й', 'র', 'ต', 'п', '◆', 'ุ', 'τ', 'r', 'น', 'ঘ', 'మ', 'q', 'ਆ', 'ி', 'н', 'з', 'ز', 'ಳ', 'ش', '́', 'ล', 'ḷ', 'ำ', '′', 'g', 'ক', '大', '±', 'ె', '◇', 'ண', 'ш', 'ก', 'Þ', 'ি', '性', 'ா', '¹', 'Э', 'ো', '长', 'М', 'Ş', 'V', '►', 'ʃ', 'ֵ', '\\\\', 'า', 'ғ', '׃', 'т', 'Z', 'κ', '¼', 'อ', '世', 'ន', 'ン', 'ও', 'َ', 'ק', 'в', 'x', '\\ue205', 'ξ', 'ড', 'נ', 'ν', '女', 'Ⓡ', 'د', 'ɨ', 'ό', 'f', 'ف', 'レ', 'Ι', '²', 'α', 'ல', 'ٰ', 'Ÿ', 'ø', 'ş', 'ò', '~', 'ʁ', 'ك', 'ؤ', 'ي', 'แ', 'Ṭ', '॒', '\\u200c', '”', 'ǔ', 'প', 'ன', 'ئ', 'ූ', 'উ', 'ন', '↔', 'ம', 'ú', 'ে', '´', '\\xa0', 'ऒ', 'ম', 'η', 'य़', 'ᠴ', 'ਿ', 'ා', 'ख़', 'ත', '\\uf146', '…', '春', '‑', 'À', 'd', '☞', 'Å', 'ᠩ', 'ι', 'ς', 'R', 'θ', 'ි', 'デ', '经', '❏', 'ス', 'ă', '়', 'ح', 'M', 'ɑ', 'ง', '骨', '॰', 'ॅ', '‐', 'р', 'ə', '♪', '≈', 'గ', '國', 'ං', 'è', '—', '記', 'ම', 'ज़', 'ऱ', 'ী', '■', 'ढ़', 'ু', 'फ़', 'ច', '일', '¡', 'Θ', '▫', 'و', '高', 'න', 'ా', '\\uf514', 'ɪ', '–', '்', '¶', 'ن', '੍', 'ā', 'ِ', 'Р', 'N', 'Ó', 'ී', 'T', 'W', 'ē', 'Τ', 'ُ', 'ঔ', 'ء', 'ห', 'ر', 'ய', 'к', 'ව', 'm', 'ŋ', 'Ч', 'ت', 'ّ', 'క', 't', 'क़', '˜', 'B', 'ס', 'ł', 'ᡠ', 'ॠ', '♫', 'Y', 'ิ', 'ы'}\n"
          ]
        }
      ],
      "source": [
        "# for i in 'शख्स':\n",
        "  # print(i)\n",
        "\n",
        "\n",
        "# hindi_sentences = [\n",
        "#     'आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।',\n",
        "#     'और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है',\n",
        "#     'जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।',\n",
        "#     'आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को',\n",
        "#     '8 सितम्‍बर, 2016 को माननीय राष्ट्रपति की स्‍वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्व में आया'\n",
        "# ]\n",
        "\n",
        "# Define the provided vocabulary set\n",
        "hindi_vocabulary_set = set(hindi_vocabulary)\n",
        "\n",
        "# Combine all sentences into one string\n",
        "combined_sentences = ''.join(hindi_sentences)\n",
        "\n",
        "# Find all unique characters in the combined sentences\n",
        "unique_chars_in_sentences = set(combined_sentences)\n",
        "\n",
        "# Find characters in the sentences that are not in the vocabulary\n",
        "missing_chars = unique_chars_in_sentences - hindi_vocabulary_set\n",
        "\n",
        "print(\"Characters in the sentences not in the vocabulary:\", missing_chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hindi_vocabulary' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index_to_hindi \u001b[38;5;241m=\u001b[39m {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mhindi_vocabulary\u001b[49m)}\n\u001b[0;32m      2\u001b[0m hindi_to_index \u001b[38;5;241m=\u001b[39m {v:k \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hindi_vocabulary)}\n\u001b[0;32m      3\u001b[0m index_to_english \u001b[38;5;241m=\u001b[39m {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(english_vocabulary)}\n",
            "\u001b[1;31mNameError\u001b[0m: name 'hindi_vocabulary' is not defined"
          ]
        }
      ],
      "source": [
        "index_to_hindi = {k:v for k,v in enumerate(hindi_vocabulary)}\n",
        "hindi_to_index = {v:k for k,v in enumerate(hindi_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dropout\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, max_seq_len):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        pos = np.arange(self.max_seq_len)[:, np.newaxis]\n",
        "        i = np.arange(self.d_model)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.d_model))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.constant(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class SentenceEmbedding(tf.keras.Model):\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super(SentenceEmbedding, self).__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
        "        self.dropout = Dropout(0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "    \n",
        "    def batch_tokenize(self, batch, start_token, end_token):\n",
        "        def tokenize(sentence, start_token, end_token):\n",
        "            sentence_word_indices = [self.language_to_index[token] for token in list(sentence)]\n",
        "            if start_token:\n",
        "                sentence_word_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indices.append(self.language_to_index[self.END_TOKEN])\n",
        "            sentence_word_indices.extend([self.language_to_index[self.PADDING_TOKEN]] * (self.max_sequence_length - len(sentence_word_indices)))\n",
        "            return tf.convert_to_tensor(sentence_word_indices, dtype=tf.int32)\n",
        "\n",
        "        tokenized = [tokenize(sentence, start_token, end_token) for sentence in batch]\n",
        "        return tf.stack(tokenized)\n",
        "\n",
        "    def call(self, x, start_token, end_token):\n",
        "        x = self.batch_tokenize(x, start_token, end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder(x)\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
